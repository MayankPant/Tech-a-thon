{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3156af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac3b3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognitionNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0d8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import moviepy.editor as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9dabfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\aryan\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from moviepy) (0.4.7)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from moviepy) (4.64.0)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from moviepy) (2.9.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from moviepy) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from moviepy) (1.21.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb8118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.50999999999999\n",
      "MoviePy - Writing audio in converted1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Please wait ...\n",
      "Speech to text conversion successfull.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import moviepy.editor as me\n",
    "\n",
    "VIDEO_FILE = \"video2.mp4\"\n",
    "OUTPUT_AUDIO_FILE = \"converted1.wav\"\n",
    "OUTPUT_TEXT_FILE = \"recognized1.txt\"\n",
    "try:\n",
    "    video_clip = me.VideoFileClip(r\"{}\".format(VIDEO_FILE))\n",
    "    print(video_clip.duration)\n",
    "    video_clip.audio.write_audiofile(r\"{}\".format(OUTPUT_AUDIO_FILE))\n",
    "    recognizer =  sr.Recognizer()\n",
    "    audio_clip = sr.AudioFile(\"{}\".format(OUTPUT_AUDIO_FILE))\n",
    "    with audio_clip as source:\n",
    "        audio_file = recognizer.record(source)\n",
    "    print(\"Please wait ...\")\n",
    "    result = recognizer.recognize_google(audio_file)\n",
    "    with open(OUTPUT_TEXT_FILE, 'w') as file:\n",
    "        file.write(result)\n",
    "        print(\"Speech to text conversion successfull.\")\n",
    "except Exception as e:\n",
    "    print(\"Attempt failed -- \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a5ba23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23c7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\n",
    "with open('recognized1.txt' , 'r') as f:\n",
    "    s = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9179cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, per):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc= nlp(text)\n",
    "    tokens=[token.text for token in doc]\n",
    "    word_frequencies={}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency=max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "    sentence_tokens= [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores:                            \n",
    "                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
    "    select_length=int(len(sentence_tokens)*per)\n",
    "    summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
    "    final_summary=[word.text for word in summary]\n",
    "    summary=''.join(final_summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62d2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(s , 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ccfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b0222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy  \n",
    "import re\n",
    "import json\n",
    "import pymongo \n",
    "import datetime\n",
    "import sys\n",
    "import xlrd\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757d9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be8e6a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\aryan\\tech a thon\\en_core_web_sm-3.8.0-py3-none-any.whl\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Requirement 'en_core_web_sm-3.8.0-py3-none-any.whl' looks like a filename, but the file does not exist\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\aryan\\\\Tech A Thon\\\\en_core_web_sm-3.8.0-py3-none-any.whl'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install en_core_web_sm-3.8.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e44452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can install a downloaded python whl file via the python package manager pip e.g.:\n",
    "\n",
    "# pip install en_core_web_sm-3.1.0-py3-none-any.whl\n",
    "\n",
    "# You can download a en_core_web_sm from this page:\n",
    "\n",
    "# https://github.com/explosion/spacy-models/releases/tag/en_core_web_sm-3.1.0\n",
    "\n",
    "# The example from the spacy front page looks easy, have you tried the commented first lines in your terminal? Example from spacy page:\n",
    "\n",
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52f1c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement en_core_web_sm (from versions: none)\n",
      "ERROR: No matching distribution found for en_core_web_sm\n"
     ]
    }
   ],
   "source": [
    "pip install en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7cf881d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2944073384.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [55]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip3 install en_core_web_sm\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9da5835b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdoc\u001b[49m\u001b[38;5;241m.\u001b[39msents\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "doc.sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5cd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good morning chetan singh i saharanpur uttar pradesh currently residing meerut uttar pradesh currently engineering undergraduate student pursuing bachelors technology computer science engineering lovely professional university phagwara punjab i.get schooling meerut uttar pradesh kendriya vidyalaya meerut i basically come farming oriented family family sister talk grandfather person farming measure odisha coming loop father mr vijendra kumar currently serving indian army army medical corps currently posted hyderabad mother mrs renu housewife i younger sister currently studying 11th standard talking hobbies include reading web novels watching\n"
     ]
    }
   ],
   "source": [
    "ignore = list(STOP_WORDS)\n",
    "s = summary.split()\n",
    "l = []\n",
    "for i in s:\n",
    "    if i not in ignore:\n",
    "        l.append(i.lower())\n",
    "set(l)\n",
    "l = \" \".join(l)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a98791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely\n",
      "student\n",
      "mrs\n",
      "reading\n",
      "undergraduate\n",
      "father\n",
      "uttar\n",
      "loop\n",
      "indian\n",
      "singh\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] \n",
    "    doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "    return result\n",
    "new_text = summary\n",
    "output = set(get_hotwords(new_text))\n",
    "most_common_list = Counter(output).most_common(10)\n",
    "for item in most_common_list:\n",
    "    print(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17880cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"words\")\n",
    "# from nltk.corpus import words\n",
    "\n",
    "# set(words.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d59c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(string):\n",
    "    \"\"\"\n",
    "    Take a string and return a list of bigrams.\n",
    "    \"\"\"\n",
    "    if string is None:\n",
    "        return \"\"\n",
    "\n",
    "    s = string.lower()\n",
    "    return [s[i : i + 2] for i in list(range(len(s) - 1))]\n",
    "\n",
    "def simon_similarity(str1, str2):\n",
    "    \"\"\"\n",
    "    Perform bigram comparison between two strings\n",
    "    and return a percentage match in decimal form.\n",
    "    \"\"\"\n",
    "    pairs1 = get_bigrams(str1)\n",
    "    pairs2 = get_bigrams(str2)\n",
    "    union = len(pairs1) + len(pairs2)\n",
    "\n",
    "    if union == 0 or union is None:\n",
    "        return 0\n",
    "\n",
    "    hit_count = 0\n",
    "    for x in pairs1:\n",
    "        for y in pairs2:\n",
    "            if x == y:\n",
    "                hit_count += 1\n",
    "                break\n",
    "    return (2.0 * hit_count) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "642ef263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21561632976615142"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simon_similarity(\" \".join(s) , \" \".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "757ca82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-search-scraper\n",
      "  Downloading youtube-search-scraper-1.0.0.tar.gz (2.4 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from youtube-search-scraper) (2.27.1)\n",
      "Collecting bot-studio\n",
      "  Downloading bot_studio-1.4.0.tar.gz (55.4 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from bot-studio->youtube-search-scraper) (4.64.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->youtube-search-scraper) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->youtube-search-scraper) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->youtube-search-scraper) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->youtube-search-scraper) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from tqdm->bot-studio->youtube-search-scraper) (0.4.4)\n",
      "Building wheels for collected packages: youtube-search-scraper, bot-studio\n",
      "  Building wheel for youtube-search-scraper (setup.py): started\n",
      "  Building wheel for youtube-search-scraper (setup.py): finished with status 'done'\n",
      "  Created wheel for youtube-search-scraper: filename=youtube_search_scraper-1.0.0-py3-none-any.whl size=2274 sha256=639b361c27902501358550f5d47f2cfe20cb90ab936df3a9a8ee5645bb6c9dbd\n",
      "  Stored in directory: c:\\users\\aryan\\appdata\\local\\pip\\cache\\wheels\\6a\\63\\71\\1cf190fc3e249d75a82843bab1be7eb9c55787ced31d291387\n",
      "  Building wheel for bot-studio (setup.py): started\n",
      "  Building wheel for bot-studio (setup.py): finished with status 'done'\n",
      "  Created wheel for bot-studio: filename=bot_studio-1.4.0-py3-none-any.whl size=55391279 sha256=61a8813a25f99ec7d8997c50a7de36269f0886be647464bdd083972a992ee09c\n",
      "  Stored in directory: c:\\users\\aryan\\appdata\\local\\pip\\cache\\wheels\\34\\bd\\42\\d1df11be0be60bb4272430ce77f26516b187fc374a607448b2\n",
      "Successfully built youtube-search-scraper bot-studio\n",
      "Installing collected packages: bot-studio, youtube-search-scraper\n",
      "Successfully installed bot-studio-1.4.0 youtube-search-scraper-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install youtube-search-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e85ebe60",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myoutube_search_scraper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\youtube_search_scraper\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbot_studio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m youtube\u001b[38;5;241m=\u001b[39m\u001b[43mbot_studio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myoutube\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bot_studio\\bot_studio.py:227\u001b[0m, in \u001b[0;36mbot_studio.__getattr__.<locals>.method\u001b[1;34m(*argss, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThanks for your feedback!!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m dynamicclass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(name, \n\u001b[0;32m    223\u001b[0m   (), \n\u001b[0;32m    224\u001b[0m   { \n\u001b[0;32m    225\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__init__\u001b[39m\u001b[38;5;124m\"\u001b[39m: set_browser_index,\n\u001b[0;32m    226\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getattr__\u001b[39m\u001b[38;5;124m\"\u001b[39m:__getattrr__})\n\u001b[1;32m--> 227\u001b[0m obj1\u001b[38;5;241m=\u001b[39mdynamicclass(\u001b[38;5;241m*\u001b[39margss,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj1\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bot_studio\\bot_studio.py:139\u001b[0m, in \u001b[0;36mbot_studio.__getattr__.<locals>.method.<locals>.set_browser_index\u001b[1;34m(self, *argss, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m global_user\n\u001b[0;32m    138\u001b[0m browseroptions\u001b[38;5;241m=\u001b[39mgetargs(argss,kwargs,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 139\u001b[0m indexnumber\u001b[38;5;241m=\u001b[39m\u001b[43mstartbrowser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbrowseroptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m=\u001b[39mindexnumber\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m=\u001b[39mname\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bot_studio\\bot_studio.py:104\u001b[0m, in \u001b[0;36mbot_studio.__getattr__.<locals>.startbrowser\u001b[1;34m(self, browseroptions)\u001b[0m\n\u001b[0;32m    102\u001b[0m res\u001b[38;5;241m=\u001b[39mrequests\u001b[38;5;241m.\u001b[39mpost(url \u001b[38;5;241m=\u001b[39m startapi, data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(browseroptions), headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m    103\u001b[0m res\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m--> 104\u001b[0m res\u001b[38;5;241m=\u001b[39m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m index\u001b[38;5;241m=\u001b[39mres[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from youtube_search_scraper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e4c50c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urllib.request.urlopen(\"https://www.youtube.com/results?search_query=lovely_professional_university\")\n",
    "res = BeautifulSoup(html , \"html.parser\")\n",
    "vids = soup.findAll(attrs={'class':'yt-uix-tile-link'})\n",
    "print(vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21317363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listen: https://quellechris360.bandcamp.com/album/deathfame\n",
      "\n",
      "Quelle Chris delivers what might be his most challenging album yet.\n",
      "\n",
      "More rap reviews: https://www.youtube.com/playlist?list=PLP4CSgl7K7ormBIO138tYonB949PHnNcP\n",
      "\n",
      "===================================\n",
      "Subscribe: http://bit.ly/1pBqGCN\n",
      "\n",
      "Patreon: https://www.patreon.com/theneedledrop\n",
      "\n",
      "Official site: http://theneedledrop.com\n",
      "\n",
      "Twitter: http://twitter.com/theneedledrop\n",
      "\n",
      "Instagram: https://www.instagram.com/afantano\n",
      "\n",
      "TikTok: https://www.tiktok.com/@theneedletok\n",
      "\n",
      "TND Twitch: https://www.twitch.tv/theneedledrop\n",
      "===================================\n",
      "\n",
      "FAV TRACKS: ALIVE AIN'T ALWAYS LIVING, KING IN BLACK, FEED THE HEADS, DEATHFAME, THE AGENCY OF THE FUTURE\n",
      "\n",
      "LEAST FAV TRACK: HELP I'M DEAD\n",
      "\n",
      "QUELLE CHRIS - DEATHFAME / 2022 / MELLO MUSIC GROUP / ABSTRACT HIP HOP\n",
      "\n",
      "7/10\n",
      "\n",
      "Y'all know this is just my opinion, right?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "soup = BeautifulSoup(requests.get('https://www.youtube.com/watch?v=57Tjvv_pCXg').content)\n",
    "pattern = re.compile('(?<=shortDescription\":\").*(?=\",\"isCrawlable)')\n",
    "description = pattern.findall(str(soup))[0].replace('\\\\n','\\n')\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bb502e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "source = requests.get(\"https://www.youtube.com/watch?v=kzLtxdJFcIg\").text\n",
    "soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "csv_file = open('YouTube Trending Titles on 12-30-18.csv','w')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Title', 'Description'])\n",
    "\n",
    "for content in soup.find_all('div', class_= \"yt-lockup-content\"):\n",
    "    try:\n",
    "        title = content.h3.a.text\n",
    "        print(title)\n",
    "\n",
    "        description = content.find('div', class_=\"yt-lockup-description yt-ui-ellipsis yt-ui-ellipsis-2\").text\n",
    "        print(description)\n",
    "\n",
    "    except Exception as e:\n",
    "        description = None\n",
    "\n",
    "    print('\\n')\n",
    "    csv_writer.writerow([title, description])\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2086c9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytubeNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pytube-12.1.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: pytube\n",
      "Successfully installed pytube-12.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install  pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2564a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Back in the day when I think of my college days, we’d find so much joy in just waiting for when the sandwich or chaat stalls would open right outside our college gate. But now seeing the kind of opportunities the kids of today have, I’m quite envious. While nostalgia hit me as I was walking around Lovely Professional University’s campus, I also realized how the children of today are spoiled for choice! \\n \\nAs I walked around Lovely Professional University nestled in the small city of Phaghwara, Jalandhar, it is one of the largest universities in India housing 18 different schools on the college campus. \\n \\nWe also got the chance to chat with the Pro-Chancellor of the college, Rashmi Mittal. She shared how the campus has a variety of state-of-the-art facilities all under one roof. The students also get a taste of implementing the theory they learn in the classrooms in on-ground situations too! Students like Neeraj Chopra are part of their impressive alumni. \\n \\nWell, if you’re looking for a holistic college experience that will help pursue your dream career, watch this video and see how LPU could be the fit for you!\\n \\n#LovelyProfessionalUniversity #curlytales  #kamiyajani #punjab #foodandtravel \\n\\nSubscribe to Curly Tales on YT ► http://bit.ly/CurlyTales\\n\\nOther Social Accounts:\\nFollow us on Facebook ►http://bit.ly/2PEaDGT\\nFollow us on Instagram ► http://bit.ly/2NQcckE\\nFor more such stories ► http://bit.ly/2MM7yrk'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "yt = YouTube(\"https://www.youtube.com/watch?v=uxv6fu8angU\")\n",
    "\n",
    "yt.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9abb942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  0 videos found\n",
      "no videos found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "# Web URL\n",
    "Web_url = \"https://www.youtube.com/results?search_query=lovely_professional_university\"\n",
    " \n",
    "# Get URL Content\n",
    "r = requests.get(Web_url)\n",
    " \n",
    "# Parse HTML Code\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    " \n",
    "# List of all video tag\n",
    "video_tags = soup.findAll({'class' : 'video-title.yt-simple-endpoint.style-scope.ytd-video-renderer'})\n",
    "print(\"Total \", len(video_tags), \"videos found\")\n",
    " \n",
    "if len(video_tags) != 0:\n",
    "    for video_tag in video_tags:\n",
    "        video_url = video_tag.find(\"a\")['href']\n",
    "        print(video_url)\n",
    "else:\n",
    "    print(\"no videos found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f483246",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/results?search_query=programming&sp=CAISBAgBEAE\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m253D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_page\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscrolldown\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m links \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma#video-title\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      9\u001b[0m     link \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(links\u001b[38;5;241m.\u001b[39mabsolute_links))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests_html.py:586\u001b[0m, in \u001b[0;36mHTML.render\u001b[1;34m(self, retries, script, wait, scrolldown, sleep, reload, timeout, keep_page)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, retries: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, script: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, wait: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, scrolldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sleep: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, timeout: Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8.0\u001b[39m, keep_page: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;124;03m\"\"\"Reloads the response in Chromium, and replaces HTML content\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    with an updated version, with JavaScript executed.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;124;03m    Chromium into your home directory (``~/.pyppeteer``).\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbrowser\u001b[49m  \u001b[38;5;66;03m# Automatically create a event loop and browser\u001b[39;00m\n\u001b[0;32m    587\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;66;03m# Automatically set Reload to False, if example URL is being used.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests_html.py:729\u001b[0m, in \u001b[0;36mHTMLSession.browser\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 729\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_browser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbrowser)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_browser\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead."
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "url = \"https://www.youtube.com/results?search_query=programming&sp=CAISBAgBEAE%253D\"\n",
    "response = session.get(url)\n",
    "response.html.render(sleep=1, keep_page = True, scrolldown = 2)\n",
    "\n",
    "for links in response.html.find('a#video-title'):\n",
    "    link = next(iter(links.absolute_links))\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12e979ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests_html\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Collecting fake-useragent\n",
      "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests_html) (2.27.1)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting parse\n",
      "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: w3lib in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests_html) (1.21.0)\n",
      "Collecting pyquery\n",
      "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting pyppeteer>=0.0.14\n",
      "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
      "Collecting websockets<11.0,>=10.0\n",
      "  Downloading websockets-10.3-cp39-cp39-win_amd64.whl (98 kB)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (1.26.9)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (4.11.3)\n",
      "Requirement already satisfied: certifi>=2021 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (2021.10.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (4.64.0)\n",
      "Collecting pyee<9.0.0,>=8.1.0\n",
      "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests_html) (0.4.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from bs4->requests_html) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->requests_html) (2.3.1)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pyquery->requests_html) (4.8.0)\n",
      "Requirement already satisfied: cssselect>0.7.9 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pyquery->requests_html) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->requests_html) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->requests_html) (3.3)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from w3lib->requests_html) (1.16.0)\n",
      "Building wheels for collected packages: bs4, fake-useragent, parse\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=02723423e8295750254942abcaf74e1810a93222fcd84316de105a9821f41e36\n",
      "  Stored in directory: c:\\users\\aryan\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "  Building wheel for fake-useragent (setup.py): started\n",
      "  Building wheel for fake-useragent (setup.py): finished with status 'done'\n",
      "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=e239c6e63d3a90b325bf70fc3efc1c59e0c57966928073095df56afd774b2f1e\n",
      "  Stored in directory: c:\\users\\aryan\\appdata\\local\\pip\\cache\\wheels\\ae\\e7\\76\\7dd44644d065268ab0e1b4fa2e802fa4bb0157717b7d6c6d92\n",
      "  Building wheel for parse (setup.py): started\n",
      "  Building wheel for parse (setup.py): finished with status 'done'\n",
      "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=1d9e1fecb0dba500e64844542a6492e0d6c5772ed249bb5969af5bb19b12419e\n",
      "  Stored in directory: c:\\users\\aryan\\appdata\\local\\pip\\cache\\wheels\\d6\\9c\\58\\ee3ba36897e890f3ad81e9b730791a153fce20caa4a8a474df\n",
      "Successfully built bs4 fake-useragent parse\n",
      "Installing collected packages: websockets, pyee, pyquery, pyppeteer, parse, fake-useragent, bs4, requests-html\n",
      "Successfully installed bs4-0.0.1 fake-useragent-0.1.11 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-html-0.10.0 websockets-10.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ede3149",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'serpapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mserpapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleSearch\n\u001b[0;32m      3\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myoutube\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_query\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogramming\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAISBAgBEAE\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m253D\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_secret_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m search \u001b[38;5;241m=\u001b[39m GoogleSearch(params)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'serpapi'"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "params = {\n",
    "  \"engine\": \"youtube\",\n",
    "  \"search_query\": \"programming\",\n",
    "  \"sp\": \"CAISBAgBEAE%253D\",\n",
    "  \"api_key\": \"your_secret_api_key\"\n",
    "}\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "\n",
    "for link in results['video_results']:\n",
    "    print(f\"Title: {link['title']}\\nLink: {link['link']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42ceac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement serpapi (from versions: none)\n",
      "ERROR: No matching distribution found for serpapi\n"
     ]
    }
   ],
   "source": [
    "pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f4ed56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def get_source(url):\n",
    "    return BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "\n",
    "soup = get_source('https://www.youtube.com/results?search_query=lovely_professional_university')\n",
    "\n",
    "for entry in soup.find_all(\"entry\"):\n",
    "    for title in entry.find_all(\"title\"):\n",
    "        print(title.text)\n",
    "    for link in entry.find_all(\"link\"):\n",
    "        print(link[\"href\"])\n",
    "    for name in entry.find_all(\"name\"):\n",
    "        print(name.text)\n",
    "    for pub in entry.find_all(\"published\"):\n",
    "        print(pub.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d8c8f5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/results?search_query=programming&sp=CAISBAgBEAE\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m253D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_page\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscrolldown\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m links \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma#video-title\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      9\u001b[0m     link \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(links\u001b[38;5;241m.\u001b[39mabsolute_links))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests_html.py:586\u001b[0m, in \u001b[0;36mHTML.render\u001b[1;34m(self, retries, script, wait, scrolldown, sleep, reload, timeout, keep_page)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, retries: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, script: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, wait: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, scrolldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sleep: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, timeout: Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8.0\u001b[39m, keep_page: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;124;03m\"\"\"Reloads the response in Chromium, and replaces HTML content\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    with an updated version, with JavaScript executed.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;124;03m    Chromium into your home directory (``~/.pyppeteer``).\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbrowser\u001b[49m  \u001b[38;5;66;03m# Automatically create a event loop and browser\u001b[39;00m\n\u001b[0;32m    587\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;66;03m# Automatically set Reload to False, if example URL is being used.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests_html.py:729\u001b[0m, in \u001b[0;36mHTMLSession.browser\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 729\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_browser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbrowser)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_browser\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead."
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "url = \"https://www.youtube.com/results?search_query=programming&sp=CAISBAgBEAE%253D\"\n",
    "response = session.get(url)\n",
    "response.html.render(sleep=1, keep_page = True, scrolldown = 2)\n",
    "\n",
    "for links in response.html.find('a#video-title'):\n",
    "    link = next(iter(links.absolute_links))\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8431a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_data(selector):\n",
    "    youtube_video_page = []\n",
    "\n",
    "    all_script_tags = selector.css('script').getall()\n",
    "\n",
    "    title = selector.css(\".title .ytd-video-primary-info-renderer::text\").get()\n",
    "\n",
    "    # https://regex101.com/r/gHeLwZ/1\n",
    "    views = int(re.search(r\"(.*)\\s\", selector.css(\".view-count::text\").get()).group().replace(\",\", \"\"))\n",
    "\n",
    "    # https://regex101.com/r/9OGwJp/1\n",
    "    likes = int(re.search(r\"(.*)\\s\", selector.css(\"#top-level-buttons-computed > ytd-toggle-button-renderer:first-child #text::attr(aria-label)\").get()).group().replace(\",\", \"\"))\n",
    "\n",
    "    date = selector.css(\"#info-strings yt-formatted-string::text\").get()\n",
    "\n",
    "    duration = selector.css(\".ytp-time-duration::text\").get()\n",
    "\n",
    "    # https://regex101.com/r/0JNma3/1\n",
    "    keywords = \"\".join(re.findall(r'\"keywords\":\\[(.*)\\],\"channelId\":\".*\"', str(all_script_tags))).replace('\\\"', '').split(\",\")\n",
    "\n",
    "    # https://regex101.com/r/9VhH1s/1\n",
    "    thumbnail = re.findall(r'\\[{\"url\":\"(\\S+)\",\"width\":\\d*,\"height\":\\d*},', str(all_script_tags))[0].split('\",')[0]\n",
    "\n",
    "    channel = {\n",
    "        # https://regex101.com/r/xFUzq5/1\n",
    "        \"id\": \"\".join(re.findall(r'\"channelId\":\"(.*)\",\"isOwnerViewing\"', str(all_script_tags))),\n",
    "        \"name\": selector.css(\"#channel-name a::text\").get(),\n",
    "        \"link\": f'https://www.youtube.com{selector.css(\"#channel-name a::attr(href)\").get()}',\n",
    "        \"subscribers\": selector.css(\"#owner-sub-count::text\").get(),\n",
    "        \"thumbnail\": selector.css(\"#img::attr(src)\").get(),\n",
    "    }\n",
    "    \n",
    "    description = selector.css(\".ytd-expandable-video-description-body-renderer span:nth-child(1)::text\").get()\n",
    "    \n",
    "    hashtags = [\n",
    "        {\n",
    "            \"name\": hash_tag.css(\"::text\").get(),\n",
    "            \"link\": f'https://www.youtube.com{hash_tag.css(\"::attr(href)\").get()}'\n",
    "        }\n",
    "        for hash_tag in selector.css(\".ytd-expandable-video-description-body-renderer a\")\n",
    "        if hash_tag.css(\"::text\").get()[0] == '#'\n",
    "    ]\n",
    "\n",
    "    # https://regex101.com/r/onRk9j/1\n",
    "    category = \"\".join(re.findall(r'\"category\":\"(.*)\",\"publishDate\"', str(all_script_tags)))\n",
    "    \n",
    "    comments_amount = int(selector.css(\"#count .count-text span:nth-child(1)::text\").get().replace(\",\", \"\"))\n",
    "\n",
    "    comments = []\n",
    "\n",
    "    for comment in selector.css(\"#contents > ytd-comment-thread-renderer\"):\n",
    "        comments.append({\n",
    "            \"author\": comment.css(\"#author-text span::text\").get().strip(),\n",
    "            \"link\": f'https://www.youtube.com{comment.css(\"#author-text::attr(href)\").get()}',\n",
    "            \"date\": comment.css(\".published-time-text a::text\").get(),\n",
    "            \"likes\": comment.css(\"#vote-count-middle::text\").get().strip(),\n",
    "            \"comment\": comment.css(\"#content-text::text\").get(),\n",
    "            \"avatar\": comment.css(\"#author-thumbnail #img::attr(src)\").get(),\n",
    "        })\n",
    "\n",
    "    suggested_videos = []\n",
    "    \n",
    "    for video in selector.css(\"ytd-compact-video-renderer\"):\n",
    "\n",
    "        suggested_videos.append({\n",
    "            \"title\": video.css(\"#video-title::text\").get().strip(),\n",
    "            \"link\": f'https://www.youtube.com{video.css(\"#thumbnail::attr(href)\").get()}',\n",
    "            \"channel_name\": video.css(\"#channel-name #text::text\").get(),\n",
    "            \"date\": video.css(\"#metadata-line span:nth-child(2)::text\").get(),\n",
    "            \"views\": video.css(\"#metadata-line span:nth-child(1)::text\").get(),\n",
    "            \"duration\": video.css(\"#overlays #text::text\").get().strip(),\n",
    "            \"thumbnail\": video.css(\"#thumbnail img::attr(src)\").get(),\n",
    "        })\n",
    "\n",
    "    youtube_video_page.append({\n",
    "      \"title\": title,\n",
    "      \"views\": views,\n",
    "      \"likes\": likes,\n",
    "      \"date\": date,\n",
    "      \"duration\": duration,\n",
    "        \"channel\": channel,\n",
    "      \"keywords\": keywords,\n",
    "      \"thumbnail\": thumbnail,\n",
    "      \"description\": description,\n",
    "        \"hashtags\": hashtags,\n",
    "        \"category\": category,\n",
    "        \"suggested_videos\": suggested_videos,\n",
    "      \"comments_amount\": comments_amount,\n",
    "      \"comments\": comments,\n",
    "    })\n",
    "\n",
    "    print(json.dumps(youtube_video_page, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a77c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
